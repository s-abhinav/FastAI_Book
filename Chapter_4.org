#+Title: Chapter 4. Under the Hood: Training a Digit Classifier
#+PROPERTY: header-args:python :session :exports both

* Running this org file
** TODO Prerequisites WIP
**** All the Fast AI dependencies.
- PyTorch
- Fast AI library
- Jupyter-Python for emacs
- conda
** In Emacs
- ~M-x conda-env-activate~ return
  fast-ai-course
- ~M-x jupyter-run-repl~
- ~C-c~ on the org file header, the line after the Title, PROPERTY: header-args ...
- ~C-c~ on each jupyter-python code block you want to run.
- ~C-c v b~ to run the whole org file

* Import libraries
#+begin_src python :results output silent
  from PIL import Image

  # Numerical and plotting libraries
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd
  import math
  import operator
  from matplotlib import rcParams

  # PyTorch
  import torch
  from torch import tensor
  import torch.nn.functional as F

  # FastAI
  from fastai.data.external import untar_data
  from fastai.data.external import URLs
  from fastai.vision.all import *
#+end_src

* Helper Functions
#+begin_src python :exports code :results output silent
  def save_image(img_tensor, filename="temp_image.png"):
      # Create the plot with show_image
      show_image(img_tensor)

      # Save the current figure to a file
      plt.savefig(filename, bbox_inches='tight')
      plt.close()  # Close the figure to avoid memory buildup

      return filename  # Return the filename passed as argument
#+end_src

#+RESULTS:

* Load images and representation analysis
** Download a sample of MNIST
#+begin_src python :exports code :results raw :exports both
  path = untar_data(URLs.MNIST_SAMPLE)
  path
#+end_src

#+RESULTS:
/Users/abhinav/.fastai/data/mnist_sample

** Load 3s and 7s

#+begin_src python :results file :exports both
  threes = (path/'train'/'3').ls().sorted()
  sevens = (path/'train'/'7').ls().sorted()
  im3_path = threes[1]
  im3 = Image.open(im3_path)
  output_path = "images/Chapter4/three_sample.png"
  im3.save(output_path)
  output_path
#+end_src

#+RESULTS:
[[file:images/Chapter4/three_sample.png]]

** NumPy array
A section of an image of 3 represented in numbers in a NumPy array
#+begin_src python :results raw :exports both
array(im3)[4:10, 4:10]
#+end_src

#+RESULTS:
: array([[  0,   0,   0,   0,   0,   0],
:        [  0,   0,   0,   0,   0,  29],
:        [  0,   0,   0,  48, 166, 224],
:        [  0,  93, 244, 249, 253, 187],
:        [  0, 107, 253, 253, 230,  48],
:        [  0,   3,  20,  20,  15,   0]], dtype=uint8)

** PyTorch Tensor
The same can be done using a PyTorch Tensor. Notice the data type at the end of the array.
#+begin_src jupyter-python :results raw :exports both
  im3_tensor = tensor(im3)
  im3_sliced = im3_tensor[4:10, 4:10]
  im3_sliced
#+end_src

#+RESULTS:
: tensor([[  0,   0,   0,   0,   0,   0],
:         [  0,   0,   0,   0,   0,  29],
:         [  0,   0,   0,  48, 166, 224],
:         [  0,  93, 244, 249, 253, 187],
:         [  0, 107, 253, 253, 230,  48],
:         [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)

** Render a section of 3 using Pandas DataFrame
#+begin_src jupyter-python :results :exports both
  df = pd.DataFrame(im3_tensor[4:15, 4:22].numpy())
  df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')
#+end_src

#+RESULTS:
#+begin_export html
<style type="text/css">
#T_ef289_row0_col0, #T_ef289_row0_col1, #T_ef289_row0_col2, #T_ef289_row0_col3, #T_ef289_row0_col4, #T_ef289_row0_col5, #T_ef289_row0_col6, #T_ef289_row0_col7, #T_ef289_row0_col8, #T_ef289_row0_col9, #T_ef289_row0_col10, #T_ef289_row0_col11, #T_ef289_row0_col12, #T_ef289_row0_col13, #T_ef289_row0_col14, #T_ef289_row0_col15, #T_ef289_row0_col16, #T_ef289_row0_col17, #T_ef289_row1_col0, #T_ef289_row1_col1, #T_ef289_row1_col2, #T_ef289_row1_col3, #T_ef289_row1_col4, #T_ef289_row1_col15, #T_ef289_row1_col16, #T_ef289_row1_col17, #T_ef289_row2_col0, #T_ef289_row2_col1, #T_ef289_row2_col2, #T_ef289_row2_col15, #T_ef289_row2_col16, #T_ef289_row2_col17, #T_ef289_row3_col0, #T_ef289_row3_col15, #T_ef289_row3_col16, #T_ef289_row3_col17, #T_ef289_row4_col0, #T_ef289_row4_col6, #T_ef289_row4_col7, #T_ef289_row4_col8, #T_ef289_row4_col9, #T_ef289_row4_col10, #T_ef289_row4_col15, #T_ef289_row4_col16, #T_ef289_row4_col17, #T_ef289_row5_col0, #T_ef289_row5_col5, #T_ef289_row5_col6, #T_ef289_row5_col7, #T_ef289_row5_col8, #T_ef289_row5_col9, #T_ef289_row5_col15, #T_ef289_row5_col16, #T_ef289_row5_col17, #T_ef289_row6_col0, #T_ef289_row6_col1, #T_ef289_row6_col2, #T_ef289_row6_col3, #T_ef289_row6_col4, #T_ef289_row6_col5, #T_ef289_row6_col6, #T_ef289_row6_col7, #T_ef289_row6_col8, #T_ef289_row6_col9, #T_ef289_row6_col14, #T_ef289_row6_col15, #T_ef289_row6_col16, #T_ef289_row6_col17, #T_ef289_row7_col0, #T_ef289_row7_col1, #T_ef289_row7_col2, #T_ef289_row7_col3, #T_ef289_row7_col4, #T_ef289_row7_col5, #T_ef289_row7_col6, #T_ef289_row7_col13, #T_ef289_row7_col14, #T_ef289_row7_col15, #T_ef289_row7_col16, #T_ef289_row7_col17, #T_ef289_row8_col0, #T_ef289_row8_col1, #T_ef289_row8_col2, #T_ef289_row8_col3, #T_ef289_row8_col4, #T_ef289_row8_col13, #T_ef289_row8_col14, #T_ef289_row8_col15, #T_ef289_row8_col16, #T_ef289_row8_col17, #T_ef289_row9_col0, #T_ef289_row9_col1, #T_ef289_row9_col2, #T_ef289_row9_col3, #T_ef289_row9_col4, #T_ef289_row9_col16, #T_ef289_row9_col17, #T_ef289_row10_col0, #T_ef289_row10_col1, #T_ef289_row10_col2, #T_ef289_row10_col3, #T_ef289_row10_col4, #T_ef289_row10_col5, #T_ef289_row10_col6, #T_ef289_row10_col17 {
  font-size: 6pt;
  background-color: #ffffff;
  color: #000000;
}
#T_ef289_row1_col5 {
  font-size: 6pt;
  background-color: #efefef;
  color: #000000;
}
#T_ef289_row1_col6, #T_ef289_row1_col13 {
  font-size: 6pt;
  background-color: #7c7c7c;
  color: #f1f1f1;
}
#T_ef289_row1_col7 {
  font-size: 6pt;
  background-color: #4a4a4a;
  color: #f1f1f1;
}
#T_ef289_row1_col8, #T_ef289_row1_col9, #T_ef289_row1_col10, #T_ef289_row2_col5, #T_ef289_row2_col6, #T_ef289_row2_col7, #T_ef289_row2_col11, #T_ef289_row2_col12, #T_ef289_row2_col13, #T_ef289_row3_col4, #T_ef289_row3_col12, #T_ef289_row3_col13, #T_ef289_row4_col1, #T_ef289_row4_col2, #T_ef289_row4_col3, #T_ef289_row4_col12, #T_ef289_row4_col13, #T_ef289_row5_col12, #T_ef289_row6_col11, #T_ef289_row9_col11, #T_ef289_row10_col11, #T_ef289_row10_col12, #T_ef289_row10_col13, #T_ef289_row10_col14, #T_ef289_row10_col15, #T_ef289_row10_col16 {
  font-size: 6pt;
  background-color: #000000;
  color: #f1f1f1;
}
#T_ef289_row1_col11 {
  font-size: 6pt;
  background-color: #606060;
  color: #f1f1f1;
}
#T_ef289_row1_col12 {
  font-size: 6pt;
  background-color: #4d4d4d;
  color: #f1f1f1;
}
#T_ef289_row1_col14 {
  font-size: 6pt;
  background-color: #bbbbbb;
  color: #000000;
}
#T_ef289_row2_col3 {
  font-size: 6pt;
  background-color: #e4e4e4;
  color: #000000;
}
#T_ef289_row2_col4, #T_ef289_row8_col6 {
  font-size: 6pt;
  background-color: #6b6b6b;
  color: #f1f1f1;
}
#T_ef289_row2_col8, #T_ef289_row2_col14, #T_ef289_row3_col14 {
  font-size: 6pt;
  background-color: #171717;
  color: #f1f1f1;
}
#T_ef289_row2_col9, #T_ef289_row3_col11 {
  font-size: 6pt;
  background-color: #4b4b4b;
  color: #f1f1f1;
}
#T_ef289_row2_col10, #T_ef289_row7_col10, #T_ef289_row8_col8, #T_ef289_row8_col10, #T_ef289_row9_col8, #T_ef289_row9_col10 {
  font-size: 6pt;
  background-color: #010101;
  color: #f1f1f1;
}
#T_ef289_row3_col1 {
  font-size: 6pt;
  background-color: #272727;
  color: #f1f1f1;
}
#T_ef289_row3_col2 {
  font-size: 6pt;
  background-color: #0a0a0a;
  color: #f1f1f1;
}
#T_ef289_row3_col3 {
  font-size: 6pt;
  background-color: #050505;
  color: #f1f1f1;
}
#T_ef289_row3_col5 {
  font-size: 6pt;
  background-color: #333333;
  color: #f1f1f1;
}
#T_ef289_row3_col6 {
  font-size: 6pt;
  background-color: #e6e6e6;
  color: #000000;
}
#T_ef289_row3_col7, #T_ef289_row3_col10 {
  font-size: 6pt;
  background-color: #fafafa;
  color: #000000;
}
#T_ef289_row3_col8 {
  font-size: 6pt;
  background-color: #fbfbfb;
  color: #000000;
}
#T_ef289_row3_col9 {
  font-size: 6pt;
  background-color: #fdfdfd;
  color: #000000;
}
#T_ef289_row4_col4 {
  font-size: 6pt;
  background-color: #1b1b1b;
  color: #f1f1f1;
}
#T_ef289_row4_col5 {
  font-size: 6pt;
  background-color: #e0e0e0;
  color: #000000;
}
#T_ef289_row4_col11 {
  font-size: 6pt;
  background-color: #4e4e4e;
  color: #f1f1f1;
}
#T_ef289_row4_col14 {
  font-size: 6pt;
  background-color: #767676;
  color: #f1f1f1;
}
#T_ef289_row5_col1 {
  font-size: 6pt;
  background-color: #fcfcfc;
  color: #000000;
}
#T_ef289_row5_col2, #T_ef289_row5_col3 {
  font-size: 6pt;
  background-color: #f6f6f6;
  color: #000000;
}
#T_ef289_row5_col4, #T_ef289_row7_col7 {
  font-size: 6pt;
  background-color: #f8f8f8;
  color: #000000;
}
#T_ef289_row5_col10, #T_ef289_row10_col7 {
  font-size: 6pt;
  background-color: #e8e8e8;
  color: #000000;
}
#T_ef289_row5_col11 {
  font-size: 6pt;
  background-color: #222222;
  color: #f1f1f1;
}
#T_ef289_row5_col13, #T_ef289_row6_col12 {
  font-size: 6pt;
  background-color: #090909;
  color: #f1f1f1;
}
#T_ef289_row5_col14 {
  font-size: 6pt;
  background-color: #d0d0d0;
  color: #000000;
}
#T_ef289_row6_col10, #T_ef289_row7_col11, #T_ef289_row9_col6 {
  font-size: 6pt;
  background-color: #060606;
  color: #f1f1f1;
}
#T_ef289_row6_col13 {
  font-size: 6pt;
  background-color: #979797;
  color: #f1f1f1;
}
#T_ef289_row7_col8 {
  font-size: 6pt;
  background-color: #b6b6b6;
  color: #000000;
}
#T_ef289_row7_col9 {
  font-size: 6pt;
  background-color: #252525;
  color: #f1f1f1;
}
#T_ef289_row7_col12 {
  font-size: 6pt;
  background-color: #999999;
  color: #f1f1f1;
}
#T_ef289_row8_col5 {
  font-size: 6pt;
  background-color: #f9f9f9;
  color: #000000;
}
#T_ef289_row8_col7 {
  font-size: 6pt;
  background-color: #101010;
  color: #f1f1f1;
}
#T_ef289_row8_col9, #T_ef289_row9_col9 {
  font-size: 6pt;
  background-color: #020202;
  color: #f1f1f1;
}
#T_ef289_row8_col11 {
  font-size: 6pt;
  background-color: #545454;
  color: #f1f1f1;
}
#T_ef289_row8_col12 {
  font-size: 6pt;
  background-color: #f1f1f1;
  color: #000000;
}
#T_ef289_row9_col5 {
  font-size: 6pt;
  background-color: #f7f7f7;
  color: #000000;
}
#T_ef289_row9_col7 {
  font-size: 6pt;
  background-color: #030303;
  color: #f1f1f1;
}
#T_ef289_row9_col12 {
  font-size: 6pt;
  background-color: #181818;
  color: #f1f1f1;
}
#T_ef289_row9_col13 {
  font-size: 6pt;
  background-color: #303030;
  color: #f1f1f1;
}
#T_ef289_row9_col14 {
  font-size: 6pt;
  background-color: #a9a9a9;
  color: #f1f1f1;
}
#T_ef289_row9_col15 {
  font-size: 6pt;
  background-color: #fefefe;
  color: #000000;
}
#T_ef289_row10_col8, #T_ef289_row10_col9 {
  font-size: 6pt;
  background-color: #bababa;
  color: #000000;
}
#T_ef289_row10_col10 {
  font-size: 6pt;
  background-color: #393939;
  color: #f1f1f1;
}
</style>
<table id="T_ef289">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_ef289_level0_col0" class="col_heading level0 col0" >0</th>
      <th id="T_ef289_level0_col1" class="col_heading level0 col1" >1</th>
      <th id="T_ef289_level0_col2" class="col_heading level0 col2" >2</th>
      <th id="T_ef289_level0_col3" class="col_heading level0 col3" >3</th>
      <th id="T_ef289_level0_col4" class="col_heading level0 col4" >4</th>
      <th id="T_ef289_level0_col5" class="col_heading level0 col5" >5</th>
      <th id="T_ef289_level0_col6" class="col_heading level0 col6" >6</th>
      <th id="T_ef289_level0_col7" class="col_heading level0 col7" >7</th>
      <th id="T_ef289_level0_col8" class="col_heading level0 col8" >8</th>
      <th id="T_ef289_level0_col9" class="col_heading level0 col9" >9</th>
      <th id="T_ef289_level0_col10" class="col_heading level0 col10" >10</th>
      <th id="T_ef289_level0_col11" class="col_heading level0 col11" >11</th>
      <th id="T_ef289_level0_col12" class="col_heading level0 col12" >12</th>
      <th id="T_ef289_level0_col13" class="col_heading level0 col13" >13</th>
      <th id="T_ef289_level0_col14" class="col_heading level0 col14" >14</th>
      <th id="T_ef289_level0_col15" class="col_heading level0 col15" >15</th>
      <th id="T_ef289_level0_col16" class="col_heading level0 col16" >16</th>
      <th id="T_ef289_level0_col17" class="col_heading level0 col17" >17</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_ef289_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_ef289_row0_col0" class="data row0 col0" >0</td>
      <td id="T_ef289_row0_col1" class="data row0 col1" >0</td>
      <td id="T_ef289_row0_col2" class="data row0 col2" >0</td>
      <td id="T_ef289_row0_col3" class="data row0 col3" >0</td>
      <td id="T_ef289_row0_col4" class="data row0 col4" >0</td>
      <td id="T_ef289_row0_col5" class="data row0 col5" >0</td>
      <td id="T_ef289_row0_col6" class="data row0 col6" >0</td>
      <td id="T_ef289_row0_col7" class="data row0 col7" >0</td>
      <td id="T_ef289_row0_col8" class="data row0 col8" >0</td>
      <td id="T_ef289_row0_col9" class="data row0 col9" >0</td>
      <td id="T_ef289_row0_col10" class="data row0 col10" >0</td>
      <td id="T_ef289_row0_col11" class="data row0 col11" >0</td>
      <td id="T_ef289_row0_col12" class="data row0 col12" >0</td>
      <td id="T_ef289_row0_col13" class="data row0 col13" >0</td>
      <td id="T_ef289_row0_col14" class="data row0 col14" >0</td>
      <td id="T_ef289_row0_col15" class="data row0 col15" >0</td>
      <td id="T_ef289_row0_col16" class="data row0 col16" >0</td>
      <td id="T_ef289_row0_col17" class="data row0 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_ef289_row1_col0" class="data row1 col0" >0</td>
      <td id="T_ef289_row1_col1" class="data row1 col1" >0</td>
      <td id="T_ef289_row1_col2" class="data row1 col2" >0</td>
      <td id="T_ef289_row1_col3" class="data row1 col3" >0</td>
      <td id="T_ef289_row1_col4" class="data row1 col4" >0</td>
      <td id="T_ef289_row1_col5" class="data row1 col5" >29</td>
      <td id="T_ef289_row1_col6" class="data row1 col6" >150</td>
      <td id="T_ef289_row1_col7" class="data row1 col7" >195</td>
      <td id="T_ef289_row1_col8" class="data row1 col8" >254</td>
      <td id="T_ef289_row1_col9" class="data row1 col9" >255</td>
      <td id="T_ef289_row1_col10" class="data row1 col10" >254</td>
      <td id="T_ef289_row1_col11" class="data row1 col11" >176</td>
      <td id="T_ef289_row1_col12" class="data row1 col12" >193</td>
      <td id="T_ef289_row1_col13" class="data row1 col13" >150</td>
      <td id="T_ef289_row1_col14" class="data row1 col14" >96</td>
      <td id="T_ef289_row1_col15" class="data row1 col15" >0</td>
      <td id="T_ef289_row1_col16" class="data row1 col16" >0</td>
      <td id="T_ef289_row1_col17" class="data row1 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_ef289_row2_col0" class="data row2 col0" >0</td>
      <td id="T_ef289_row2_col1" class="data row2 col1" >0</td>
      <td id="T_ef289_row2_col2" class="data row2 col2" >0</td>
      <td id="T_ef289_row2_col3" class="data row2 col3" >48</td>
      <td id="T_ef289_row2_col4" class="data row2 col4" >166</td>
      <td id="T_ef289_row2_col5" class="data row2 col5" >224</td>
      <td id="T_ef289_row2_col6" class="data row2 col6" >253</td>
      <td id="T_ef289_row2_col7" class="data row2 col7" >253</td>
      <td id="T_ef289_row2_col8" class="data row2 col8" >234</td>
      <td id="T_ef289_row2_col9" class="data row2 col9" >196</td>
      <td id="T_ef289_row2_col10" class="data row2 col10" >253</td>
      <td id="T_ef289_row2_col11" class="data row2 col11" >253</td>
      <td id="T_ef289_row2_col12" class="data row2 col12" >253</td>
      <td id="T_ef289_row2_col13" class="data row2 col13" >253</td>
      <td id="T_ef289_row2_col14" class="data row2 col14" >233</td>
      <td id="T_ef289_row2_col15" class="data row2 col15" >0</td>
      <td id="T_ef289_row2_col16" class="data row2 col16" >0</td>
      <td id="T_ef289_row2_col17" class="data row2 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_ef289_row3_col0" class="data row3 col0" >0</td>
      <td id="T_ef289_row3_col1" class="data row3 col1" >93</td>
      <td id="T_ef289_row3_col2" class="data row3 col2" >244</td>
      <td id="T_ef289_row3_col3" class="data row3 col3" >249</td>
      <td id="T_ef289_row3_col4" class="data row3 col4" >253</td>
      <td id="T_ef289_row3_col5" class="data row3 col5" >187</td>
      <td id="T_ef289_row3_col6" class="data row3 col6" >46</td>
      <td id="T_ef289_row3_col7" class="data row3 col7" >10</td>
      <td id="T_ef289_row3_col8" class="data row3 col8" >8</td>
      <td id="T_ef289_row3_col9" class="data row3 col9" >4</td>
      <td id="T_ef289_row3_col10" class="data row3 col10" >10</td>
      <td id="T_ef289_row3_col11" class="data row3 col11" >194</td>
      <td id="T_ef289_row3_col12" class="data row3 col12" >253</td>
      <td id="T_ef289_row3_col13" class="data row3 col13" >253</td>
      <td id="T_ef289_row3_col14" class="data row3 col14" >233</td>
      <td id="T_ef289_row3_col15" class="data row3 col15" >0</td>
      <td id="T_ef289_row3_col16" class="data row3 col16" >0</td>
      <td id="T_ef289_row3_col17" class="data row3 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_ef289_row4_col0" class="data row4 col0" >0</td>
      <td id="T_ef289_row4_col1" class="data row4 col1" >107</td>
      <td id="T_ef289_row4_col2" class="data row4 col2" >253</td>
      <td id="T_ef289_row4_col3" class="data row4 col3" >253</td>
      <td id="T_ef289_row4_col4" class="data row4 col4" >230</td>
      <td id="T_ef289_row4_col5" class="data row4 col5" >48</td>
      <td id="T_ef289_row4_col6" class="data row4 col6" >0</td>
      <td id="T_ef289_row4_col7" class="data row4 col7" >0</td>
      <td id="T_ef289_row4_col8" class="data row4 col8" >0</td>
      <td id="T_ef289_row4_col9" class="data row4 col9" >0</td>
      <td id="T_ef289_row4_col10" class="data row4 col10" >0</td>
      <td id="T_ef289_row4_col11" class="data row4 col11" >192</td>
      <td id="T_ef289_row4_col12" class="data row4 col12" >253</td>
      <td id="T_ef289_row4_col13" class="data row4 col13" >253</td>
      <td id="T_ef289_row4_col14" class="data row4 col14" >156</td>
      <td id="T_ef289_row4_col15" class="data row4 col15" >0</td>
      <td id="T_ef289_row4_col16" class="data row4 col16" >0</td>
      <td id="T_ef289_row4_col17" class="data row4 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_ef289_row5_col0" class="data row5 col0" >0</td>
      <td id="T_ef289_row5_col1" class="data row5 col1" >3</td>
      <td id="T_ef289_row5_col2" class="data row5 col2" >20</td>
      <td id="T_ef289_row5_col3" class="data row5 col3" >20</td>
      <td id="T_ef289_row5_col4" class="data row5 col4" >15</td>
      <td id="T_ef289_row5_col5" class="data row5 col5" >0</td>
      <td id="T_ef289_row5_col6" class="data row5 col6" >0</td>
      <td id="T_ef289_row5_col7" class="data row5 col7" >0</td>
      <td id="T_ef289_row5_col8" class="data row5 col8" >0</td>
      <td id="T_ef289_row5_col9" class="data row5 col9" >0</td>
      <td id="T_ef289_row5_col10" class="data row5 col10" >43</td>
      <td id="T_ef289_row5_col11" class="data row5 col11" >224</td>
      <td id="T_ef289_row5_col12" class="data row5 col12" >253</td>
      <td id="T_ef289_row5_col13" class="data row5 col13" >245</td>
      <td id="T_ef289_row5_col14" class="data row5 col14" >74</td>
      <td id="T_ef289_row5_col15" class="data row5 col15" >0</td>
      <td id="T_ef289_row5_col16" class="data row5 col16" >0</td>
      <td id="T_ef289_row5_col17" class="data row5 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_ef289_row6_col0" class="data row6 col0" >0</td>
      <td id="T_ef289_row6_col1" class="data row6 col1" >0</td>
      <td id="T_ef289_row6_col2" class="data row6 col2" >0</td>
      <td id="T_ef289_row6_col3" class="data row6 col3" >0</td>
      <td id="T_ef289_row6_col4" class="data row6 col4" >0</td>
      <td id="T_ef289_row6_col5" class="data row6 col5" >0</td>
      <td id="T_ef289_row6_col6" class="data row6 col6" >0</td>
      <td id="T_ef289_row6_col7" class="data row6 col7" >0</td>
      <td id="T_ef289_row6_col8" class="data row6 col8" >0</td>
      <td id="T_ef289_row6_col9" class="data row6 col9" >0</td>
      <td id="T_ef289_row6_col10" class="data row6 col10" >249</td>
      <td id="T_ef289_row6_col11" class="data row6 col11" >253</td>
      <td id="T_ef289_row6_col12" class="data row6 col12" >245</td>
      <td id="T_ef289_row6_col13" class="data row6 col13" >126</td>
      <td id="T_ef289_row6_col14" class="data row6 col14" >0</td>
      <td id="T_ef289_row6_col15" class="data row6 col15" >0</td>
      <td id="T_ef289_row6_col16" class="data row6 col16" >0</td>
      <td id="T_ef289_row6_col17" class="data row6 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_ef289_row7_col0" class="data row7 col0" >0</td>
      <td id="T_ef289_row7_col1" class="data row7 col1" >0</td>
      <td id="T_ef289_row7_col2" class="data row7 col2" >0</td>
      <td id="T_ef289_row7_col3" class="data row7 col3" >0</td>
      <td id="T_ef289_row7_col4" class="data row7 col4" >0</td>
      <td id="T_ef289_row7_col5" class="data row7 col5" >0</td>
      <td id="T_ef289_row7_col6" class="data row7 col6" >0</td>
      <td id="T_ef289_row7_col7" class="data row7 col7" >14</td>
      <td id="T_ef289_row7_col8" class="data row7 col8" >101</td>
      <td id="T_ef289_row7_col9" class="data row7 col9" >223</td>
      <td id="T_ef289_row7_col10" class="data row7 col10" >253</td>
      <td id="T_ef289_row7_col11" class="data row7 col11" >248</td>
      <td id="T_ef289_row7_col12" class="data row7 col12" >124</td>
      <td id="T_ef289_row7_col13" class="data row7 col13" >0</td>
      <td id="T_ef289_row7_col14" class="data row7 col14" >0</td>
      <td id="T_ef289_row7_col15" class="data row7 col15" >0</td>
      <td id="T_ef289_row7_col16" class="data row7 col16" >0</td>
      <td id="T_ef289_row7_col17" class="data row7 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_ef289_row8_col0" class="data row8 col0" >0</td>
      <td id="T_ef289_row8_col1" class="data row8 col1" >0</td>
      <td id="T_ef289_row8_col2" class="data row8 col2" >0</td>
      <td id="T_ef289_row8_col3" class="data row8 col3" >0</td>
      <td id="T_ef289_row8_col4" class="data row8 col4" >0</td>
      <td id="T_ef289_row8_col5" class="data row8 col5" >11</td>
      <td id="T_ef289_row8_col6" class="data row8 col6" >166</td>
      <td id="T_ef289_row8_col7" class="data row8 col7" >239</td>
      <td id="T_ef289_row8_col8" class="data row8 col8" >253</td>
      <td id="T_ef289_row8_col9" class="data row8 col9" >253</td>
      <td id="T_ef289_row8_col10" class="data row8 col10" >253</td>
      <td id="T_ef289_row8_col11" class="data row8 col11" >187</td>
      <td id="T_ef289_row8_col12" class="data row8 col12" >30</td>
      <td id="T_ef289_row8_col13" class="data row8 col13" >0</td>
      <td id="T_ef289_row8_col14" class="data row8 col14" >0</td>
      <td id="T_ef289_row8_col15" class="data row8 col15" >0</td>
      <td id="T_ef289_row8_col16" class="data row8 col16" >0</td>
      <td id="T_ef289_row8_col17" class="data row8 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_ef289_row9_col0" class="data row9 col0" >0</td>
      <td id="T_ef289_row9_col1" class="data row9 col1" >0</td>
      <td id="T_ef289_row9_col2" class="data row9 col2" >0</td>
      <td id="T_ef289_row9_col3" class="data row9 col3" >0</td>
      <td id="T_ef289_row9_col4" class="data row9 col4" >0</td>
      <td id="T_ef289_row9_col5" class="data row9 col5" >16</td>
      <td id="T_ef289_row9_col6" class="data row9 col6" >248</td>
      <td id="T_ef289_row9_col7" class="data row9 col7" >250</td>
      <td id="T_ef289_row9_col8" class="data row9 col8" >253</td>
      <td id="T_ef289_row9_col9" class="data row9 col9" >253</td>
      <td id="T_ef289_row9_col10" class="data row9 col10" >253</td>
      <td id="T_ef289_row9_col11" class="data row9 col11" >253</td>
      <td id="T_ef289_row9_col12" class="data row9 col12" >232</td>
      <td id="T_ef289_row9_col13" class="data row9 col13" >213</td>
      <td id="T_ef289_row9_col14" class="data row9 col14" >111</td>
      <td id="T_ef289_row9_col15" class="data row9 col15" >2</td>
      <td id="T_ef289_row9_col16" class="data row9 col16" >0</td>
      <td id="T_ef289_row9_col17" class="data row9 col17" >0</td>
    </tr>
    <tr>
      <th id="T_ef289_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_ef289_row10_col0" class="data row10 col0" >0</td>
      <td id="T_ef289_row10_col1" class="data row10 col1" >0</td>
      <td id="T_ef289_row10_col2" class="data row10 col2" >0</td>
      <td id="T_ef289_row10_col3" class="data row10 col3" >0</td>
      <td id="T_ef289_row10_col4" class="data row10 col4" >0</td>
      <td id="T_ef289_row10_col5" class="data row10 col5" >0</td>
      <td id="T_ef289_row10_col6" class="data row10 col6" >0</td>
      <td id="T_ef289_row10_col7" class="data row10 col7" >43</td>
      <td id="T_ef289_row10_col8" class="data row10 col8" >98</td>
      <td id="T_ef289_row10_col9" class="data row10 col9" >98</td>
      <td id="T_ef289_row10_col10" class="data row10 col10" >208</td>
      <td id="T_ef289_row10_col11" class="data row10 col11" >253</td>
      <td id="T_ef289_row10_col12" class="data row10 col12" >253</td>
      <td id="T_ef289_row10_col13" class="data row10 col13" >253</td>
      <td id="T_ef289_row10_col14" class="data row10 col14" >253</td>
      <td id="T_ef289_row10_col15" class="data row10 col15" >187</td>
      <td id="T_ef289_row10_col16" class="data row10 col16" >22</td>
      <td id="T_ef289_row10_col17" class="data row10 col17" >0</td>
    </tr>
  </tbody>
</table>
#+end_export

* Image processing
** Create tensors for each 3 and 7 using Python list comprehension to store their images
Consequently verify the number of images loaded in the tensors.
#+begin_src python :results raw :exports both
  seven_tensors = [tensor(Image.open(o)) for o in sevens]
  three_tensors = [tensor(Image.open(o)) for o in threes]
  len(three_tensors), len(seven_tensors)
#+end_src

#+RESULTS:
(6131, 6265)

#+begin_src python :exports both :results file
  save_image(three_tensors[1], "images/Chapter4/three_tensors.png")
#+end_src

#+RESULTS:
[[file:images/Chapter4/three_tensors.png]]

** Stack the images, convert to float(~.float()~) then scale the range between 0 and 1 (~/255~)
.shape returns the dimension of the resulting tensor, which is 6131 images, each having 28 x 28 pixels.

#+begin_src python :exports both
  stacked_sevens = torch.stack(seven_tensors).float() / 255
  stacked_threes = torch.stack(three_tensors).float() / 255
  stacked_threes.shape
#+end_src

#+RESULTS:
: torch.Size([6131, 28, 28])

The PyTorch ~mean~ operaion require that the types be float, and with float types, the range is expected to be between 0 and 1.

** Why Normalize by Dividing by 255? (ChatGPT)
**** Numerical Stability:
Machine learning models (especially those based on neural networks) perform better when input values are within a small, consistent range. Values like 
[0,1] are easier for the model to process than [0,255], as they reduce the risk of numerical instability during training (e.g., exploding gradients).
**** Gradient Descent Works Better:
If the inputs are large (e.g., [0,255]), gradients during backpropagation can become excessively large, leading to unstable weight updates.
Scaling to [0,1] ensures that gradients remain in a manageable range.
**** Consistency Across Datasets:
Normalization ensures a consistent input scale across different datasets. This is particularly important when pre-trained models are used, as they often expect normalized inputs.
**** Pixel Values Represent Intensity:
A pixel value of 255 represents the maximum intensity, and 0 represents no intensity. Dividing by 255 maps these to 1 and 0, respectively, preserving their relative intensity while scaling them to a smaller range.

** Length of a tensor's shape is its rank
#+begin_src python :exports both
len(stacked_threes.shape)
#+end_src

#+RESULTS:
: 3

** A tensor's rank can also be retrieved using ndim
#+begin_src python :exports both
stacked_threes.ndim
#+end_src

#+RESULTS:
: 3

** What does the ideal 3 look like?
Mean of all the images along dimension 0, which is the list of all images in the tensor.
#+begin_src python :exports both :results file
  mean3 = stacked_threes.mean(0)
  save_image(mean3, "images/Chapter4/mean3.png")
#+end_src

#+RESULTS:
[[file:images/Chapter4/mean3.png]]


** The ideal 7
#+begin_src python :exports both :results file
  mean7 = stacked_sevens.mean(0)
  save_image(mean7, "images/Chapter4/mean7.png")
#+end_src

#+RESULTS:
[[file:images/Chapter4/mean7.png]]

** Sample 3
#+begin_src python :exports both :results file
  a_3 = stacked_threes[1]
  save_image(a_3, "images/Chapter4/stacked_threes.png")
#+end_src

#+RESULTS:
[[file:images/Chapter4/stacked_threes.png]]

* Number recognition
The method that the book uses for number recognition is measuring the ~distance~ of a handwritten number with the ideal 3 or 7 calculated above using mean.
There are two ways of achieving this using:
1. The ~mean absolute difference~ or ~L1 norm~.
2. The ~root mean squared error~ (RMSE) or ~L2 norm~.

** a_3 distances from mean3
#+begin_src python :exports both :results output
  dist_3_abs = (a_3 - mean3).abs().mean()
  dist_3_sqr = ((a_3 - mean3) ** 2).mean().sqrt()
  print(dist_3_abs, dist_3_sqr)
#+end_src

#+RESULTS:
: tensor(0.1114) tensor(0.2021)

** a_3 distances from mean7
#+begin_src python :exports both :results output
  dist_7_abs = (a_3 - mean7).abs().mean()
  dist_7_sqr = ((a_3 - mean7) ** 2).mean().sqrt()
  print(dist_7_abs, dist_7_sqr)
#+end_src

#+RESULTS:
: tensor(0.1586) tensor(0.3021)

** Instead of writing python expressions for these calculations, Pytorch already provides these calculations in functions
These are ~F.l1_loss~ and ~F.mse_loss~
#+begin_src python :exports both :results output
  print(F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt())
#+end_src

#+RESULTS:
: tensor(0.1586) tensor(0.3021)

* Jargons
A ~tensor~ is a ~multidimensional data structure~ used to represent data in machine learning and other computational fields.
- The ~rank~ (or order) of a tensor refers to the number of axes (or dimensions) it has.
  Example: A scalar has rank 0, a vector has rank 1, a matrix has rank 2, and so on.
- The ~shape~ of a tensor is a tuple that specifies the size of each axis (or dimension).
  Example: A tensor with shape (3, 4) has 2 dimensions (rank 2), with the first axis of size 3 and the second axis of size 4.

* Graph functions
** Plot
*** Code
#+begin_src python :results silent
  import matplotlib.pyplot as plt
  import numpy as np

  def plot_function(
      f,
      x_range=(-2, 2),
      steps=100,
      title=None,
      tx=None,
      ty=None,
      figsize=(6, 4),
      colors={"background": '#2C3539', "line": 'white', "title": 'white', "axis": 'white', "grid": 'gray'},
      grid_style='--',
      output_file=None
  ):
      """
      Plots a mathematical function with minimal required arguments.

      Parameters:
          f (function): The mathematical function to plot.
          x_range (tuple): Range for x-axis values as (min, max). Default: (-2, 2).
          steps (int): Number of points for evaluating the function. Default: 100.
          title (str): Title of the plot. If None, no title is shown.
          tx (str): Label for the x-axis. Default: None.
          ty (str): Label for the y-axis. Default: None.
          figsize (tuple): Size of the figure (width, height). Default: (6, 4).
          colors (dict): A dictionary for color settings (background, line, title, axis, grid). Default: preset colors.
          grid_style (str): Line style for grid. Default: '--'.
          output_file (str): File name to save the plot. If None, the plot is displayed.
      """

      # Generate x values and evaluate the function
      x = np.linspace(*x_range, steps)
      y = f(x)

      # Unpack colors
      bg_color = colors.get("background", '#2C3539')
      line_color = colors.get("line", 'white')
      title_color = colors.get("title", 'white')
      axis_color = colors.get("axis", 'white')
      grid_color = colors.get("grid", 'gray')

      # Create the plot
      fig, ax = plt.subplots(figsize=figsize)
      ax.set_facecolor(bg_color)
      fig.patch.set_facecolor(bg_color)

      # Plot the function
      ax.plot(x, y, color=line_color)

      # Set labels and title
      if title:
          ax.set_title(title, color=title_color, fontsize=11)
      if tx:
          ax.set_xlabel(tx, color=axis_color, fontsize=10)
      if ty:
          ax.set_ylabel(ty, color=axis_color, fontsize=10)

      # Customize ticks
      ax.tick_params(axis='x', colors=axis_color)
      ax.tick_params(axis='y', colors=axis_color)

      # Add gridlines
      ax.axhline(0, color='red', linewidth=0.5)
      ax.axvline(0, color='red', linewidth=0.5)
      ax.grid(True, color=grid_color, linestyle=grid_style)

      # Save or show the plot
      if output_file:
          fig.savefig(output_file, format='svg' if output_file.endswith('.svg') else 'png')
          plt.close(fig)
          print(output_file)  # Return the file path for consistency
      else:
          plt.show()

  # # Example usage
  # plot_function(
  #     lambda x: x**2 - 2 * x + 1,
  #     title=r"$f(x) = x^2 - 2x + 1$",
  #     output_file="quadratic.svg"
  # )

  # plot_function(
  #     np.sin,
  #     title=r"$f(x) = \sin(x)$",
  #     output_file="sine.svg"
  # )
#+end_src

**** Example

#+begin_src python :results file link :file "images/Chapter4/quadratic.svg" :var output_file="images/Chapter4/quadratic.svg" :exports both
  plot_function(
      lambda x: x**2 - 2*x + 1,
      title=r"$f(x) = x^2 - 2x + 1$",
      output_file=output_file
  )
#+end_src

#+RESULTS:
[[file:images/Chapter4/quadratic.svg]]


** Scatter
**** Code
  :PROPERTIES:
  :CUSTOM_ID: scatter-plot-code
  :END:
#+begin_src python :results silent
  import matplotlib.pyplot as plt
  import numpy as np
  import torch

  def show_preds(
      time,
      speed,
      preds,
      ax=None,
      figsize=(6, 4),
      scatter_color='blue',
      pred_color='red',
      output_file=None
  ):
      """
      Plots true data points and predictions.

      Parameters:
          time (array-like): X-axis values.
          speed (array-like): True Y-axis values.
          preds (torch.Tensor): Predicted Y-axis values (PyTorch tensor).
          ax (matplotlib.axes._subplots.AxesSubplot, optional): Matplotlib Axes object to plot on.
          figsize (tuple, optional): Figure size (width, height).
          scatter_color (str, optional): Color for the true data points.
          pred_color (str, optional): Color for the prediction points.
          output_file (str, optional): Path to save the plot as an SVG file. If None, shows interactively.
      """
      colors={"background": '#2C3539', "line": 'white', "title": 'white', "axis": 'white', "grid": 'gray'}

      bg_color = colors.get("background", '#2C3539')

      if ax is None:
          fig, ax = plt.subplots(figsize=figsize)
      else:
          fig = ax.figure

      ax.set_facecolor(bg_color)
      fig.patch.set_facecolor(bg_color)

      # Convert preds to numpy if it's a torch tensor
      preds_np = preds.detach().cpu().numpy() if torch.is_tensor(preds) else np.array(preds)

      # Plot true values and predictions
      ax.scatter(time, speed, color=scatter_color, label="True Data")
      ax.scatter(time, preds_np, color=pred_color, label="Predictions")

      # Add labels, legend, and grid
      ax.set_xlabel("Time")
      ax.set_ylabel("Speed")
      ax.legend()
      ax.grid(True)

      # Save or show the plot
      if output_file:
          fig.savefig(output_file, format='svg')
          plt.close(fig)
          print(output_file)  # Output filename for Org-mode integration
      else:
          plt.show()

  def show_multiple_preds(
      datasets,  # List of (time, speed, preds) tuples
      titles=None,
      figsize=(10, 5),
      output_file=None
  ):
      """
      Plots multiple sets of true data points and predictions on subplots using a dark theme.

      Parameters:
          datasets (list of tuples): List of (time, speed, preds) tuples.
          titles (list of str, optional): Titles for each subplot.
          figsize (tuple, optional): Figure size (width, height).
          output_file (str, optional): Path to save the plot as a PNG file.
      """
      colors = {
          "background": '#2C3539',
          "line": 'white',
          "title": 'white',
          "axis": 'white',
          "grid": 'gray',
          "true_data": 'green',  # Color for true data points
          "preds": 'orange'  # Color for predictions
      }

      num_plots = len(datasets)

      fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(18, 9), constrained_layout=True)
      plt.tight_layout()

      if num_plots == 1:
          axes = [axes]  # Ensure axes is iterable for a single subplot

      # Flatten the axes array so we can iterate over it
      axes = axes.flatten()

      # Loop through each axis and adjust properties
      for i, ax in enumerate(axes):
          ax.set_facecolor(colors["background"])
          ax.set_title(f"Plot {i+1}", color=colors["title"], fontsize=6)  # Adjust title font size
          ax.tick_params(axis="x", colors=colors["axis"], labelsize=4)  # Smaller x-tick labels
          ax.tick_params(axis="y", colors=colors["axis"], labelsize=4)  # Smaller y-tick labels

      fig.patch.set_facecolor(colors["background"])

      for i, (time, speed, preds) in enumerate(datasets):
          ax = axes[i]

          # Convert preds to numpy if it's a torch tensor
          preds_np = preds.detach().cpu().numpy() if torch.is_tensor(preds) else np.array(preds)

          # Set background color
          ax.set_facecolor(colors["background"])

          # Plot true values and predictions
          ax.scatter(time, speed, color=colors["true_data"], label="True Data", s=4)
          ax.scatter(time, preds_np, color=colors["preds"], label="Predictions", s=4)

          # Set labels and grid
          ax.set_xlabel("Time", color=colors["axis"], fontsize=5)
          ax.set_ylabel("Speed", color=colors["axis"], fontsize=5)
          ax.legend(fontsize=3)
          ax.grid(True)

          # Set subplot title
          if titles and i < len(titles):
              ax.set_title(titles[i], color=colors["title"])

          # Customize axis ticks
          ax.tick_params(axis='x', colors=colors["axis"])
          ax.tick_params(axis='y', colors=colors["axis"])

      # Save or show the plot
      if output_file:
          fig.savefig(output_file, format='svg', dpi=300, facecolor=colors["background"])
          plt.close(fig)
          print(output_file)  # Output filename for Org-mode integration
      else:
          plt.show()
#+end_src

See [[#scatter-plot-example][Scatter plot example]]
* Notes
** Stack
#+begin_src python :results silent
    stacked_sevens = torch.stack(seven_tensors).float()/255
    stacked_threes = torch.stack(three_tensors).float()/255
    mean3 = stacked_threes.mean(0)
    mean7 = stacked_sevens.mean(0)
#+end_src

#+RESULTS:

** Distance a3 with 3
#+begin_src python :results output :exports both
a_3 = stacked_threes[1]
dist_3_abs = (a_3 - mean3).abs().mean()
dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()
print(dist_3_abs,dist_3_sqr)
#+end_src

#+RESULTS:
: tensor(0.1114) tensor(0.2021)

** Distance a3 with 7
#+begin_src python :results output :exports both
  dist_7_abs = (a_3 - mean7).abs().mean()
  dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()
  print(dist_7_abs,dist_7_sqr)
#+end_src

#+RESULTS:
: tensor(0.1586) tensor(0.3021)

** Loss
#+begin_src python :results output :exports both
print(F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt())
#+end_src

#+RESULTS:
: tensor(0.1586) tensor(0.3021)

** Broadcasting
Broadcasting automatically expands arrays or tensors of smaller shapes to match larger ones for element-wise operations without duplicating data.

#+begin_src python :results output :exports both
  valid_3_tens = torch.stack([tensor(Image.open(o))
                              for o in (path/'valid'/'3').ls()])
  valid_3_tens = valid_3_tens.float()/255
  valid_7_tens = torch.stack([tensor(Image.open(o))
                              for o in (path/'valid'/'7').ls()])
  valid_7_tens = valid_7_tens.float()/255
  print(valid_3_tens.shape,valid_7_tens.shape)
#+end_src

#+RESULTS:
: torch.Size([1010, 28, 28]) torch.Size([1028, 28, 28])

*** Mean absolute error
#+begin_src python :results output :exports both
  def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))
  print(mnist_distance(a_3, mean3))
#+end_src

#+RESULTS:
: tensor(0.1114)

#+begin_src python :results output :exports both
valid_3_dist = mnist_distance(valid_3_tens, mean3)
print(valid_3_dist, valid_3_dist.shape)
#+end_src

#+RESULTS:
: tensor([0.1634, 0.1145, 0.1363,  ..., 0.1105, 0.1111, 0.1640]) torch.Size([1010])

#+begin_src python :results output :exports both
  def is_3(x): return mnist_distance(x,mean3) < mnist_distance(x,mean7)
  print(is_3(a_3), is_3(a_3).float(), is_3(valid_3_tens))
#+end_src

#+RESULTS:
: tensor(True) tensor(1.) tensor([True, True, True,  ..., True, True, True])

*** Accuracy
#+begin_src python :results output :exports both
  accuracy_3s =      is_3(valid_3_tens).float().mean()
  accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()

  print(accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2)
#+end_src

#+RESULTS:
: tensor(0.9168) tensor(0.9854) tensor(0.9511)

** Tensor gradient
#+begin_src python :results silent
  def f(x): return x**2
  xt = tensor(3.).requires_grad_()
  yt = f(xt)
  yt.backward()
  xt.grad
#+end_src

#+RESULTS:

#+begin_src python :results output :exports both
xt = tensor([3.,4.,10.]).requires_grad_()
print(xt)
#+end_src

#+RESULTS:
: tensor([ 3.,  4., 10.], requires_grad=True)


*** Vector
#+begin_src python :results output :exports both
xt = tensor([3.,4.,10.]).requires_grad_()
print(xt)
#+end_src

#+RESULTS:
: tensor([ 3.,  4., 10.], requires_grad=True)

#+begin_src python :results output :exports both
def f(x): return (x**2).sum()

yt = f(xt)
yt

yt.backward()
print(xt.grad)
#+end_src

#+RESULTS:
: tensor([ 6.,  8., 20.])

* An End-to-End SGD Example
In this section, we will use the machine learning classifier algorithm to improve the loss.
The steps are:
1. ~Weight~ initialization - randomization of parameter values
2. ~Prediction~ calculation
3. ~Loss~ calculation
4. ~Gradient~ calculation
5. ~Weight~ stepping
6. ~Repeat~
7. ~Stop~ when loss is good enough

** Ground truths
To start with, let us set some ground truths for speed over time.
- time is seeded in a range of 0 to 20
- speed follows the quadratic function -> speed = ax^2 + bx + c where x is time.
#+begin_src python :results output :exports both
  time = torch.arange(0,20).float()
  speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1
  print(time, speed)
#+end_src

#+RESULTS:
: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,
:         14., 15., 16., 17., 18., 19.]) tensor([68.6557, 53.6008, 37.7409, 29.7709, 27.8447, 16.0008, 11.1875,  1.8000,
:          6.9471, -0.4572,  2.9723,  3.8262,  4.1937, 10.4011, 11.4446, 23.3833,
:         29.5072, 46.3586, 50.0157, 63.8796])

** Functions
- Quadratic function
- Mean squared error
#+begin_src python :results silent
  def quadratic_f(t, params):
      a,b,c = params
      return a*(t**2) + (b*t) + c

  def mse(preds, targets): return ((preds-targets)**2).mean()
#+end_src

** Step 1: Initialize the paramaters
First, we initialize the parameters to random values and tell PyTorch
that we want to track their gradients using requires_grad_:

#+begin_src python :results output :exports both
  params = torch.randn(3).requires_grad_()
  print(params)
#+end_src

#+RESULTS:
: tensor([-0.3448, -1.3952, -1.8983], requires_grad=True)

** Step 2: Calculate the predictions
Next we calculate the predictions

#+begin_src python :results output :exports both
  preds = quadratic_f(time, params)
  print(preds)
#+end_src

#+RESULTS:
: tensor([  -1.8983,   -3.6384,   -6.0681,   -9.1875,  -12.9965,  -17.4952,
:          -22.6835,  -28.5615,  -35.1291,  -42.3864,  -50.3333,  -58.9699,
:          -68.2962,  -78.3120,  -89.0176, -100.4128, -112.4976, -125.2721,
:         -138.7363, -152.8901], grad_fn=<AddBackward0>)

Let’s create a little function to see how close our
predictions are to our targets, and take a look:

#+begin_src python :results output :eval no
  def show_preds(preds, ax=None):
      if ax is None: ax=plt.subplots()[1]
      ax.scatter(time, speed)
      ax.scatter(time, to_np(preds), color='red')
      ax.set_ylim(-300,100)

  show_preds(preds)
#+end_src

The code from the book to generate the predictions chart is not very intuitive; It relies on variable state outside the function and also does not work on my machine. See [[#scatter-plot-code][Scatter plot code]] for my own implementation with the help of ChatGPT.

*** Predictions
:PROPERTIES:
:CUSTOM_ID: scatter-plot-example
:END:
#+NAME: predictions

#+begin_src python :results file link :file "images/Chapter4/predictions.svg" :var output_file="images/Chatper4/predictions.svg" :exports both
  # Sample data
  time = torch.arange(0,20).float()
  speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1

  def f(t, params):
      a,b,c = params
      return a*(t**2) + (b*t) + c

  def mse(preds, targets): return ((preds-targets)**2).mean()

  params = torch.randn(3).requires_grad_()
  preds = f(time, params)

  # Save to an SVG file
  show_preds(
      time,
      speed,
      preds,
      figsize=(8, 5),
      scatter_color='green',
      pred_color='orange',
      output_file=output_file
  )
#+end_src

#+RESULTS:
[[file:images/Chapter4/predictions.svg]]

#+NAME: time, speed, params
#+begin_src python :results output :exports both
print(time, speed, preds)
#+end_src

#+RESULTS: time, speed, params
: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,
:         14., 15., 16., 17., 18., 19.]) tensor([60.1585, 63.1165, 44.4548, 33.7128, 23.2169, 15.6517,  6.2902,  7.5810,
:         -1.8243,  3.8606, -4.7698,  0.8213,  9.4670, 10.5033, 18.2512, 24.4078,
:         37.4249, 45.3417, 57.3947, 67.9377]) tensor([-3.4358e-01, -1.9125e-02,  1.0572e+00,  2.8854e+00,  5.4655e+00,
:          8.7974e+00,  1.2881e+01,  1.7717e+01,  2.3305e+01,  2.9644e+01,
:          3.6735e+01,  4.4579e+01,  5.3174e+01,  6.2521e+01,  7.2619e+01,
:          8.3470e+01,  9.5073e+01,  1.0743e+02,  1.2053e+02,  1.3439e+02],
:        grad_fn=<AddBackward0>)

#+RESULTS: predictions
[[file:images/Chapter4/predictions.svg]]


** Step 3: Calculate the loss

We calculate the loss as follows:

#+begin_src python :results output :exports both
  loss = mse(preds, speed)
  print(loss)
#+end_src

#+RESULTS:
: tensor(9882.2656, grad_fn=<MeanBackward0>)

Our goal is now to improve this. To do that, we’ll need to know the gradients.

** Step 4: Calculate the gradients

The next step is to calculate the gradients, or an approximation of how the parameters need to change:

#+begin_src python :results output :exports both
loss.backward()
print(params.grad)
#+end_src

#+RESULTS:
: tensor([-32213.8848,  -2093.8638,   -165.3856])

#+begin_src python :results output :exports both
print(params.grad * 1e-5)
#+end_src

#+RESULTS:
: tensor([-0.3221, -0.0209, -0.0017])

We can use these gradients to improve our parameters. We’ll
need to pick a learning rate (we’ll discuss how to do that
in practice in the next chapter; for now, we’ll just use
1e-5 or 0.00001):

#+begin_src python :results output :exports both
print(params)
#+end_src

#+RESULTS:
: tensor([-0.3448, -1.3952, -1.8983], requires_grad=True)

** Step 5: Step the weights
This is ~one~ iteration of gradient descent.

Now we need to update the parameters based
on the gradients we just calculated:

#+begin_src python :results silent
  lr = 1e-5 # lr, learning rate
  params.data -= lr * params.grad.data
  params.grad = None
  preds = quadratic_f(time, params)
#+end_src

#+begin_src python :results output :exports both
  print(mse(preds, speed))
#+end_src

#+RESULTS:
: tensor(2404.8325, grad_fn=<MeanBackward0>)

*** The ~apply_step~ function comprising of most of the machine learning classifier algorightm.
#+begin_src python :results silent
  def apply_step(params, prn=True):
      # 1. Initialize paramaters (params)
      preds = quadratic_f(time, params) # 2. Calculate predictions
      loss = mse(preds, speed) # 3. Calculate loss
      loss.backward() # 4. Calculate gradient
      params.data -= lr * params.grad.data # 5. Step the weights
      params.grad = None # clear grad to prevent accumulation
      if prn: print(loss.item())
      return preds
#+end_src

** Step 6: Repeat
#+begin_src python :results output :exports both
  for i in range(10):
      apply_step(params)
#+end_src

#+RESULTS:
: 2404.83251953125
: 989.8635864257812
: 722.0978393554688
: 671.4180908203125
: 661.8177490234375
: 659.99072265625
: 659.634765625
: 659.55712890625
: 659.5321655273438
: 659.5172729492188


** We can see the evolution of the predictions over multiple iterations
- Yellow dot is prediction
- Green dot is ground truth

  Notice how the yellow curve approaches the green curve on every iteration.

#+begin_src python :results file link :file "images/Chapter4/speed_predictions_12.svg" :var output_file="images/Chapter4/speed_predictions_12.svg" :exports both
  # Save to an SVG file
  # time and speed stay the same for all plots
  datasets = [(time, speed, apply_step(params)) for _ in range(12)]

  # Save multiple plots in a single SVG
  show_multiple_preds(
      datasets,
      output_file=output_file
  )
#+end_src

#+RESULTS:
[[file:images/Chapter4/speed_predictions_12.svg]]

** Summary of what was done so far
1. Start with weights
   a. If starting from scratch, it's random
   b. or use a pre trained model (transfer learning)
2. Use the model to predict
   a. Compare ouputs of the model with our targets using our loss function
3. Calculate the gradients to know how to improve the weights
4. We then iterate until the change in loss improvement is negligible. It's like the good-enough? function in SICP.
